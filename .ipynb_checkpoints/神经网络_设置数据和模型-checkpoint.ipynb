{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置数据和模型\n",
    "\n",
    "\n",
    "\n",
    "## 数据预处理\n",
    "关于数据预处理我们有3个常用的符号，数据矩阵X，假设其尺寸是[N x D]（N是数据样本的数量，D是数据的维度）\n",
    "\n",
    "####  均值减法和归一化\n",
    "**均值减法（Mean subtraction）**是预处理最常用的形式。它对数据中每个独立特征减去平均值，**从几何上可以理解为在每个维度上都将数据云的中心都迁移到原点。**  \n",
    "* 在numpy中，该操作可以通过代码`X -= np.mean(X, axis=0)`实现。  \n",
    "* 而对于图像，更常用的是对所有像素都减去一个值（平均值），可以用`X -= np.mean(X)`实现，也可以在3个颜色通道上分别操作。\n",
    "\n",
    "**归一化（Normalization）**是指将数据的所有维度都归一化，**使其数值范围都近似相等**。有两种常用方法可以实现归一化。\n",
    "* 第一种是先对数据做零中心化（zero-centered）处理，然后每个维度都除以其标准差，实现代码为`X /= np.std(X, axis=0)`。\n",
    "* 第二种方法是对每个维度都做归一化，使得每个维度的最大和最小值是1和-1。\n",
    "这个预处理操作只有在确信不同的输入特征有不同的数值范围（或计量单位）时才有意义，但要注意预处理操作的重要性几乎等同于学习算法本身。  \n",
    "\n",
    "*在图像处理中，由于像素的数值范围几乎是一致的（都在0-255之间），所以进行这个额外的预处理步骤并不是很必要。*\n",
    "\n",
    "***\n",
    "![](http://cs231n.github.io/assets/nn2/prepro1.jpeg)\n",
    "一般数据预处理流程：  \n",
    "* 左边：原始的2维输入数据。\n",
    "* 中间：在每个维度上都减去平均值后得到零中心化数据，现在数据云是以原点为中心的。\n",
    "* 右边：每个维度都除以其标准差来调整其数值范围。红色的线指出了数据各维度的数值范围，在中间的零中心化数据的数值范围不同，但在右边归一化数据中数值范围相同。\n",
    "***\n",
    "\n",
    "#### PCA和白化（看看就好，不会使用）\n",
    "**PCA和白化（Whitening）**是另一种预处理形式。在这种处理中，先对数据进行零中心化处理，然后计算协方差矩阵，它展示了数据中的相关性结构。  \n",
    "```\n",
    "假设输入数据矩阵X的尺寸为[N x D]\n",
    "X -= np.mean(X, axis = 0) # 对数据进行零中心化(重要)\n",
    "cov = np.dot(X.T, X) / X.shape[0] # 得到数据的协方差矩阵\n",
    "```\n",
    "数据协方差矩阵的第(i, j)个元素是数据第i个和第j个维度的协方差。具体来说，该矩阵的对角线上的元素是方差。还有，协方差矩阵是对称和半正定的。我们可以对数据协方差矩阵进行SVD（奇异值分解）运算。\n",
    "`U,S,V = np.linalg.svd(cov)`\n",
    "U的列是特征向量，S是装有奇异值的1维数组（因为cov是对称且半正定的，所以S中元素是特征值的平方）。为了去除数据相关性，将已经零中心化处理过的原始数据投影到特征基准上：\n",
    "`Xrot = np.dot(X,U) # 对数据去相关性`\n",
    "注意U的列是标准正交向量的集合（范式为1，列之间标准正交），所以可以把它们看做标准正交基向量。因此，投影对应x中的数据的一个旋转，旋转产生的结果就是新的特征向量。如果计算**Xrot**的协方差矩阵，将会看到它是对角对称的。**np.linalg.svd**的一个良好性质是在它的返回值U中，特征向量是按照特征值的大小排列的。我们可以利用这个性质来对数据降维，只要使用前面的小部分特征向量，丢弃掉那些包含的数据没有**方差**的维度。 这个操作也被称为主成分分析（ [Principal Component Analysis](https://link.zhihu.com/?target=http%3A//en.wikipedia.org/wiki/Principal_component_analysis) 简称PCA）降维：\n",
    "`Xrot_reduced = np.dot(X, U[:,:100]) # Xrot_reduced 变成 [N x 100]`\n",
    "经过上面的操作，将原始的数据集的大小由[N x D]降到了[N x 100]，留下了数据中包含最大方差的100个维度。通常使用PCA降维过的数据训练线性分类器和神经网络会达到非常好的性能效果，同时还能节省时间和存储器空间。\n",
    "\n",
    "\n",
    "最后一个在实践中会看见的变换是白化（whitening）。白化操作的输入是特征基准上的数据，然后对每个维度除以其特征值来对数值范围进行归一化。该变换的几何解释是：如果数据服从多变量的高斯分布，那么经过白化后，数据的分布将会是一个均值为零，且协方差相等的矩阵。该操作的代码如下：\n",
    "\n",
    "\n",
    "```\n",
    "# 对数据进行白化操作:\n",
    "# 除以特征值 \n",
    "Xwhite = Xrot / np.sqrt(S + 1e-5)\n",
    "```\n",
    "\n",
    "*警告：夸大的噪声。注意分母中添加了1e-5（或一个更小的常量）来防止分母为0。该变换的一个缺陷是在变换的过程中可能会夸大数据中的噪声，这是因为它将所有维度都拉伸到相同的数值范围，这些维度中也包含了那些只有极少差异性(方差小)而大多是噪声的维度。在实际操作中，这个问题可以用更强的平滑来解决（例如：采用比1e-5更大的值）。*\n",
    "\n",
    "\n",
    "---\n",
    "![](http://cs231n.github.io/assets/nn2/prepro2.jpeg)\n",
    "PCA/白化。\n",
    "* 左边是二维的原始数据。\n",
    "* 中间：经过PCA操作的数据。可以看出数据**首先是零中心**的，然后**变换到了数据协方差矩阵的基准轴上**。这样就对数据进行了解相关（协方差矩阵变成对角阵）。* 右边：每个维度都被特征值调整数值范围，将数据协方差矩阵变为单位矩阵。从几何上看，就是对数据在各个方向上拉伸压缩，使之变成服从高斯分布的一个数据点分布。\n",
    "---\n",
    "\n",
    "---\n",
    "我们可以使用CIFAR-10数据将这些变化可视化出来。CIFAR-10训练集的大小是50000x3072，其中每张图片都可以拉伸为3072维的行向量。我们可以计算[3072 x 3072]的协方差矩阵然后进行奇异值分解（比较耗费计算性能），那么经过计算的特征向量看起来是什么样子呢？\n",
    "\n",
    "![](http://cs231n.github.io/assets/nn2/cifar10pca.jpeg)\n",
    "\n",
    "最左：一个用于演示的集合，含49张图片。左二：3072个特征值向量中的前144个。靠前面的特征向量解释了数据中大部分的方差，可以看见它们与图像中较低的频率相关。第三张是49张经过了PCA降维处理的图片，展示了144个特征向量。这就是说，展示原始图像是每个图像用3072维的向量，向量中的元素是图片上某个位置的像素在某个颜色通道中的亮度值。而现在每张图片只使用了一个144维的向量，其中每个元素表示了特征向量对于组成这张图片的贡献度。为了让图片能够正常显示，需要将144维度重新变成基于像素基准的3072个数值。因为U是一个旋转，可以通过乘以U.transpose()[:144,:]来实现，然后将得到的3072个数值可视化。可以看见图像变得有点模糊了，这正好说明前面的特征向量获取了较低的频率。然而，大多数信息还是保留了下来。最右：将“白化”后的数据进行显示。其中144个维度中的方差都被压缩到了相同的数值范围。然后144个白化后的数值通过乘以U.transpose()[:144,:]转换到图像像素基准上。现在较低的频率（代表了大多数方差）可以忽略不计了，较高的频率（代表相对少的方差）就被夸大了。\n",
    "\n",
    "---\n",
    "\n",
    "**实践操作**。在这个笔记中提到PCA和白化主要是为了介绍的完整性，实际上在卷积神经网络中并不会采用这些变换。然而对数据进行零中心化操作还是非常重要的，对每个像素进行归一化也很常见。\n",
    "\n",
    "**常见错误**。进行预处理很重要的一点是：任何预处理策略（比如数据均值）都只能在训练集数据上进行计算，算法训练完毕后再应用到验证集或者测试集上。例如，如果先计算整个数据集图像的平均值然后每张图片都减去平均值，最后将整个数据集分成训练/验证/测试集，那么这个做法是错误的。**应该怎么做呢？应该先分成训练/验证/测试集，只是从训练集中求图片平均值，然后各个集（训练/验证/测试集）中的图像再减去这个平均值。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 权重初始化\n",
    "我们已经看到如何构建一个神经网络的结构并对数据进行预处理，但是在开始训练网络之前，还需要初始化网络的参数。\n",
    "\n",
    "**错误：全零初始化。**让我们从应该避免的错误开始。在训练完毕后，虽然不知道网络中每个权重的最终值应该是多少，但如果数据经过了恰当的归一化的话，就可以假设所有权重数值中大约一半为正数，一半为负数。这样，一个听起来蛮合理的想法就是把这些权重的初始值都设为0吧，因为在期望上来说0是最合理的猜测。这个做法错误的！因为如果网络中的每个神经元都计算出同样的输出，然后它们就会在反向传播中计算出同样的梯度，从而进行同样的参数更新。**换句话说，如果权重被初始化为同样的值，神经元之间就失去了不对称性的源头。**、\n",
    "\n",
    "**小随机数初始化。**因此，权重初始值要非常接近0又不能等于0。**解决方法就是将权重初始化为很小的数值，以此来打破对称性。**  \n",
    "其思路是：如果神经元刚开始的时候是随机且不相等的，那么它们将计算出不同的更新，并将自身变成整个网络的不同部分。小随机数权重初始化的实现方法是：W = 0.01 * np.random.randn(D,H)。其中randn函数是基于零均值和标准差的一个高斯分布（译者注：国内教程一般习惯称均值参数为期望）来生成随机数的。根据这个式子，每个神经元的权重向量都被初始化为一个随机向量，而这些随机向量又服从一个多变量高斯分布，这样在输入空间中，所有的神经元的指向是随机的。也可以使用均匀分布生成的随机数，但是从实践结果来看，对于算法的结果影响极小。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for Deeplearing",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
